![[스크린샷 2024-12-10 오후 6.11.24.png]]
# 1단계: 문제 이해 및 설계 범위 확정
- 입력하는 단어의 자동완성 기준?
- 몇 개의 자동 완성 검색어가 표현되어야 하는지?
- 검색어를 고르는 기준?
- 맞춤법 검사 기능도 제공? - 검색어 자동완성 이외에 추가적인 편의기능 제공 하는가?
- 질의 언어는?
- 대문자, 특수 문자의 처리도 해야 하는가?
- 트래픽은 얼마나?
## 요구사항 정리
- 빠른 응답 속도
	- 페이스북 검색어 자동완성 시스템에 관련한 문서 에서의 응답 속도는 100밀리초 이내여야 한다고 한다
- 사용자가 입력 한 단어와의 연관성이 있어야 한다
- 시스템의 계산 결과는 인기도 등의 순위 모델에 의해 정렬되어 있어야 한다
- 많은 트래픽을 감당 가능하도록 스케일아웃이 되어야 한다
- 고가용성: 시스템 일부에 장애가 발생 하여도 시스템은 계속 사용 가능해야 함
## 개략적인 규모 추정
- 검색어 자동완성 특성 상, 사용자가 입력중인 상태여도 request 를 날리게 됨.
  (이건 입력 이벤트 시간제한을 두면 되지 않을까? 생각도 하지만, 일단 생각 멈춤)
	- search?q=d
	- search?q=di
	- search?q=din
	- search?q=dinn
	- search?q=dinne
	- search?q=dinner
- 대략 초당 24,000 건이라는 QPS 가 발생 할 가능성 있음
  (= 1000만 사용자 x 10질의 / 일 × 20자 / 24시간 / 3600초)
# 2 단계: 개략적 설계안 제시 및 동의 구하기
시스템은 두 부분으로 나뉜다
- 데이터 수집 서비스
- 질의 서비스
## 데이터 수집 서비스
질의문, 사용 빈도를 저장하는 테이블 존재 - 빈도 테이블 (frequency table)
![[스크린샷 2024-12-10 오후 6.37.26.png]]
## 질의 서비스
사용자가 tw 를 검색창에 입력 하면 아래의 top 5 자동완성 검색어가 표시되어야 한다
![[스크린샷 2024-12-10 오후 6.38.18.png]]
데이터 양이 아주 많아지면 RDBMS 데이터베이스 병목 현상 발생 가능성 있음
# 3단계: 상세 설계
초반 안으로 나뉘어 진 설계는 설계 시작점으로 나쁘지 않다고 함
- 데이터 수집 서비스
- 데이터 질의 서비스
컴포넌트 몇 개를 골라 보다 상세히 설계 진행
- 트라이(trie) 자료구조
- 데이터 수집 서비스
- 질의 서비스
- 규모 확장이 가능한 저장소
- 트라이 연산
## 트라이 자료구조
> [! trie : 접두어 트리(prefix tree)]
> ![[스크린샷 2024-12-10 오후 6.54.01.png]]
> 문자열들을 간략하게 저장 할 수 있는 자료구조
> retrieval 에서 따온 것으로, 문자열을 꺼내는 연산에 초점을 맞추어 설계된 자료구조
> - 트라이는 트리 형태의 자료구조
> - 이 트리의 루트 노드는 빈 문자열을 나타냄
> - 각 노드는 글자를 하나 저장하며 26개 (해당 글자 다음에 등장 할 수 있는 모든 글자의 개수)의 자식 노드를 가질 수 있다
> - 각 트리 노드는 하나의 단어, 또는 접두 문자열을 나타낸다

- 이번 아이디어는 [참고문헌>2,3] 을 차용하였다
- 트라이 자료구조는 인터넷에 많으므로 본 챕터는 응답 시간 줄이기에 초점을 맞춤
위의 트라이 자료구조에 먼저 이야기 했던 빈도 테이블을 적용 해 보면 아래와 같아짐
![[스크린샷 2024-12-10 오후 6.55.33.png]]
### 용어 정리
- p: 접두어(prefix)의 길이
- n: 트라이 안에 있는 노드 개수
- c: 주어진 노드의 자식 노드 개수
#### 가장 많이 사용된 질의어 k개는 다음과 같이 찾을 수 있다
- 접두어를 표현하는 노드를 찾는다. 시간 복잡도 O(p)
- 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드를 찾는다. 시간 복잡도 O(c)
- 유효 노드들을 정렬하여 가장 인기있는 검색어 k개를 찾는다. 시간 복잡도 O(c log c)
#### 사용자가 be 만 입력 했을 때?
![[스크린샷 2024-12-10 오후 7.00.53.png]]
위 경우 최악의 경우 트리 전체를 탐색해야 함
아래의 방법으로 최적화 가능
1. 접두어의 최대 길이 제한
2. 각 노드에 인기 검색어를 캐시
##### 접두어 최대 길이 제한
- 사용자는 너무 긴 검색어를 입력하는 경우는 적음. 따라서 p 값은 작은 정수값(50 같은) 이라고 가정해도 안전
- 접두어 노드를 찾는 단계의 시간 복잡도는 O(p) 에서 O(1) 로 바뀜
##### 노드에 인기 검색어 캐시
- 캐시를 이용하여 top 5 검색어 질의 시간 복잡도를 엄청나게 낮춤
- 각 노드에 질의어를 저장 할 공간이 많이 필요하게 됨
	- 빠른 응답 속도가 아주 중요할 때는 이 정도 저장공간을 희생할 만한 가치가 있음
- 아래는 개선된 트라이 구조
![[스크린샷 2024-12-10 오후 7.14.13.png]]
따라서 최악의 경우에도 O(1)로 시간 복잡도가 개선 된다
## 데이터 수집 서비스
- 매일 수천만 건의 질의가 입력될 텐데 그 때마다 트라이를 갱신하면 질의 서비스는 심각하게 느려짐
- 일단 트라이가 만들어지고 나면 인기 검색어는 자주 바뀌지 않을 것
- 용례가 바뀌어도 서비스의 토대는 자주 바뀌지 않을 것.
![[스크린샷 2024-12-10 오후 7.17.50.png]]
### 데이터 분석 서비스 로그
- 데이터 분석 서비스 로그에는 원본 데이터가 보관됨
- 새로운 데이터가 추가 될 뿐 수정은 이루어지지 않음
![[스크린샷 2024-12-10 오후 7.19.26.png]]
### 로그 취합 서버
- 데이터 로그는 양이 엄청나고 데이터 형식도 제각각인 경우가 많음
- 데이터 취합 방식은 우리 서비스의 용례에 따라 달라질 수도 있다
	- 트위터와 같이 실시간성이 중요하다면 데이터 취합 텀을 짧게 가져가야 함
### 취합된 데이터
![[스크린샷 2024-12-10 오후 7.21.59.png]]
#### 작업 서버
- 트라이 자료구조를 만들고 트라이 데이터베이스에 저장하는 역할을 담당
#### 트라이 캐시
- 트라이 캐시는 분산 시스템
- 트라이 데이터를 메모리에 유지하고 읽기 연산 성능을 높인다
- 매주 트라이 데이터베이스의 스냅샷을 떠 갱신(갱신 주기는 서비스에 따라 다름)

#### 트라이 데이터베이스
선택지 2개 존재
1. 문서 저장소
	- MongoDB
2. 키-값 저장소
	아래 로직을 적용 하면 해시 테이블 형태로 변환 가능
	- 트라이에 보관 된 모든 접두어를 해시테이블 키로 변환
	- 각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값으로 변환
	![[스크린샷 2024-12-10 오후 7.25.34.png]]
#### 질의 서비스
- 기존 질의 서비스의 속도 개선
![[스크린샷 2024-12-10 오후 7.28.14.png]]
- ajax 요청으로 개선
- 브라우저 캐싱
	- 자동완성 검색어 제안 결과는 짧은 시간안에 자주 바뀌지 않음. 구글에서 채택 중
	  ![[스크린샷 2024-12-10 오후 7.31.18.png]]
		- cache-control: private
			해당 응답이 요청을 보낸 사용자의 캐시에만 보관 될 수 있으며 공용 캐시에저장 되어서는 안된다
		- max-age=3600
			한 시간 동안 캐시 결과를 저장
- 데이터 샘플링
	- 모든 질의 결과를 로깅하도록 하면 CPU 자원과 저장 공간을 엄청나게 소진함.
	- N 개 요청 가운데 1개만 로깅 하도록 하면 좋음
## 트라이 연산
### 트라이 생성
- 작업 서버가 담당함
- 데이터 분석 서비스의 로그나 데이터베이스로부터 취합된 데이터를 이용
### 트라이 갱신
![[스크린샷 2024-12-10 오후 7.36.57.png]]
1. 매 주 한 번 갱신
2. 트라이의 각 노드를 개별적으로 갱신
	본 예제 에서는 채택하지 않은 방법. 트라이가 작을 때 고려 해 볼만 함
### 검색어 삭제
![[스크린샷 2024-12-10 오후 7.37.30.png]]
- 트라이 캐시 앞에 필터 계층을 두고 부적절한 질의어가 반환되지 않도록 하면 됨
- 이렇게 하면 필터 규칙에 따라 검색 결과를 자유롭게 변경 할 수 있음
## 저장소 규모 확장
- 첫 글자를 기준으로 샤딩
	하지만 이러면 데이터를 균등하게 나누기 어려움.
	- 세 대로 나누든
	- 두 대로 나누든
	- 26 대로 나누든
- 과거 질의 데이터의 패턴을 분석하여 샤딩
	![[스크린샷 2024-12-10 오후 7.41.25.png]]
	아래 두 경우의 데이터 갯수가 비슷하다면 특정 시점을 기준으로 샤딩 기준을 바꾸는 방식
	- s 로 시작하는 단어의 집합
	- u, v, w, x, y, z 로 시작하는 단어의 집합
# 4단계: 마무리
상세 설계를 마치면 면접관은 이런 질문을 할 수 있음
- 다국어 어떻게 지원?
	- 비영어권 국가에서 사용하는 언어를 지원하려면 트라이에 유니코드 데이터를 저장해야 한다
- 국가별로 인기 검색어 순위가 다르다면?
	- 국가별로 다른 트라이를 사용하도록 하면 됨
	- CDN 에 저장하여 응답 속도를 높이는 방법도 생각 해 볼 수 있음
- 실시간으로 변하는 검색어의 추이를 반영하려면 어떻게?
	현재 시스템에서는 아래의 이유로 적합하지 못함
	- 작업 서버가 매 주 한 번씩만 돌도록 되어 있어, 적절하게 트라이 갱신 어려움
	- 설사 때맞춰 서버가 실행된다 해도, 트라이 구성하는데 너무 많은 시간이 소요됨
실시간 검색어 자동완성 구축은 복잡한 문제임. 책에서 간단히 다루기 어려움. 
다음의 키워드 참고
- 샤딩을 통해 작업 대상 데이터의 양을 줄인다
- 순위 모델을 바꾸어 최근 검색어에 보다 높은 가중치 부여
- 데이터가 스트림 형태로 올 수 있음
	스트림 프로세싱에는 특별한 종류의 시스템이 필요함
	- 아파치 하둡 맵리듀스
	- 아파치 스파크 스트리밍
	- 아파치 스톰
	- 아파치 카프카
---
# 참고 문헌
1. [The Life of a Typeahead Query](https://www.facebook.com/notes/facebook-engineering/the-life-of-a-typeahead-query/389105248919/)
2. [How We Built Prefixy: A Scalable Prefix Search Service for Powering Autocomplete](https://medium.com/@prefixyteam/how-we-built-prefixy-a-scalable-prefix-search-service-for-powering-autocomplete-c20f98e2eff1)
3. [Prefix Hash Tree An Indexing Data Structure over Distributed Hash Tables](https://people.eecs.berkeley.edu/~sylvia/papers/pht.pdf)
4. [MongoDB wikipedia](https://en.wikipedia.org/wiki/MongoDB)
5. [Unicode frequently asked questions](https://www.unicode.org/faq/basic_q.html)
6. [Apache hadoop](https://hadoop.apache.org/)
7. [Spark streaming](https://spark.apache.org/streaming/)
8. [Apache storm](https://storm.apache.org/)
9. [Apache kafka](https://kafka.apache.org/documentation/)

