### 광고 클릭 이벤트 집계 


#### 데이터 모델 

- 원시 데이터: 디버깅에 유리하며, 집계 결과 데이터가 손실되었을 때 이를 복구할 수 있는 백업 역할을 한다. -> 카산드라, InfluxDB  추천
- 집계 결과 데이터: 실제 질의 시 성능 면에서 유리하므로 주로 이 데이터를 활용한다.


#### 계략적 설계안 
![image](https://github.com/user-attachments/assets/f362e2ec-6408-4d89-8db4-87881146f96e)


#### (1) 비동기 처리 

- 동기로 처리할 경우 트래픽이 갑자기 증가하여 발생하는 이벤트 수가 소비자의 처리 용량을 훨씬 넘어서는 경우, 소비자는 메모리 부족 오류 등의 예기치 않은 문제를 겪을 수 있다.

- 따라서, 카프카 큐를 도입하여 생산자와 소비자의 결합을 끊는 것이 좋다. 그 결과 전체 프로세스는 비동기 방식으로 동작하게 되고, 생산자와 소비자의 규모를 독립적으로 확장해 나갈 수 있다. 


#### (2) 왜 집계 결과를 DB에 바로 넣지 않고 큐를 거치는가? 

- 네트워크 지연, 프로세스 크래시, DB 장애, 트랜잭션 실패 등의 이유로 DB에 바로 쓰는 과정에서 중복 저장되거나 저장이 누락될 수 있음
- 집계 결과는 중복되거나 누락되면 안 되는 민감한 데이터이기 때문에, exactly-once 처리 보장이 중요하다. 큐를 중간에 두는 것은 이런 처리를 안정적으로 구현하기 위한 전략이다.


#### 집계 서비스 
- 맵리듀스 프레임워크를 적용
  - 맵 노드 : 각 집계 노드로 데이터 분배 
  - 집계 노드 : 각 데이터의 집계를 수행
  - 리듀스 노드 : 결과값을 축약(리듀스)


Q. 맵노드 대신 카프카가 처리하고 집계노드가 카프카를 구독하고 있으면 되지 않을까 ? -> ad_id % 파티션 수 로 할 경우 카프카 이용할 수 있을 것으로 보임 


#### 전달 보장

- 정확히 한번을 처리하기 위해 

![image](https://github.com/user-attachments/assets/bc433397-41ef-4d24-b446-25bbf50d863d)

-> HDFS나 S3 같은 외부 파일 저장소에 오프셋을 기록하면 된다. 

